{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMtCozOnlW1sbGnIEpToiJU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Diffusers/blob/main/stable_diffusion_seeds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install the necessary libraries**"
      ],
      "metadata": {
        "id": "r9OodoWsBtEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface huggingface_hub"
      ],
      "metadata": {
        "id": "n50dFEJV6YW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers"
      ],
      "metadata": {
        "id": "Y01NOtK16mJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/diffusers.git\n",
        "!pip install transformers scipy ftfy"
      ],
      "metadata": {
        "id": "TDUelRrP636L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline"
      ],
      "metadata": {
        "id": "GYmy9QFZ7lIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohMS-MdG6Onl"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Login to HuggingFace, get a write token**"
      ],
      "metadata": {
        "id": "T-PEzNjUB8cH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "login()"
      ],
      "metadata": {
        "id": "ufonPnc6B4VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup the pipeline to use the stable-diffusion-vl-5 model**"
      ],
      "metadata": {
        "id": "0ek_019hCDoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)"
      ],
      "metadata": {
        "id": "8UezSONAB6lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    revision=\"fp16\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True,\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "j2oFJ_dA9IwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A function to display the generated images**"
      ],
      "metadata": {
        "id": "WOHpfEI0CNmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid"
      ],
      "metadata": {
        "id": "KD4l5AmG9NE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set the constants**"
      ],
      "metadata": {
        "id": "35wYBz77CYrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = 4\n",
        "\n",
        "width = 512\n",
        "height = 512"
      ],
      "metadata": {
        "id": "khnbgm2Q_jxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latents Generation\n",
        "In order to reuse the seeds we need to generate the latents ourselves. Otherwise, the pipeline will do it internally and we won't have a way to replicate them.\n",
        "\n",
        "**Latents are the initial random Gaussian noise that gets transformed to actual images during the diffusion process.**\n",
        "\n",
        "To generate them, we'll use a different random seed for each latent, and we'll save them so we can reuse them later."
      ],
      "metadata": {
        "id": "V7TqRKdGCaav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = torch.Generator(device=device)\n",
        "\n",
        "latents = None\n",
        "seeds = []\n",
        "for _ in range(num_images):\n",
        "    # Get a new random seed, store it and use it as the generator state\n",
        "    seed = generator.seed()\n",
        "    seeds.append(seed)\n",
        "    generator = generator.manual_seed(seed)\n",
        "\n",
        "    image_latents = torch.randn(\n",
        "        (1, pipe.unet.in_channels, height // 8, width // 8),\n",
        "        generator = generator,\n",
        "        device = device\n",
        "    )\n",
        "    latents = image_latents if latents is None else torch.cat((latents, image_latents))\n",
        "\n",
        "# latents should have shape (4, 4, 64, 64) in this case\n",
        "latents.shape"
      ],
      "metadata": {
        "id": "4K2mKWnh_nLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Images with our Latents\n",
        "\n",
        "We are now ready to generate the images. **We'll send the pipeline the latents we want to use. If we don't, the pipeline will generate a new set for us.**"
      ],
      "metadata": {
        "id": "HRmkMRZSCqJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Labrador in the style of Vermeer\"\n",
        "\n",
        "with torch.autocast(\"cuda\"):\n",
        "    images = pipe(\n",
        "        [prompt] * num_images,\n",
        "        guidance_scale=7.5,\n",
        "        latents = latents,\n",
        "    )[0]"
      ],
      "metadata": {
        "id": "z83G8ljq_pyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display the generated images**"
      ],
      "metadata": {
        "id": "QLX9qBSyC37i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_grid(images, 2, 2)"
      ],
      "metadata": {
        "id": "-pvf7EI0AVOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get the seed for the fourth image**"
      ],
      "metadata": {
        "id": "F9STp6cyC90H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = seeds[3]   # fourth one\n",
        "seed"
      ],
      "metadata": {
        "id": "_jBD7J0KBFm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We could just have reused `latents[3]` instead. But just taking note of the seeds will be enough te replicate the generation any time we like.**"
      ],
      "metadata": {
        "id": "eEqIO-NtDJWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator.manual_seed(seed)\n",
        "\n",
        "latents = torch.randn(\n",
        "    (1, pipe.unet.in_channels, height // 8, width // 8),\n",
        "    generator = generator,\n",
        "    device = device\n",
        ")"
      ],
      "metadata": {
        "id": "pisfabN9BIrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we repeat the generation (of a single image) with these latents and the same prompt, we should get the same image as before:"
      ],
      "metadata": {
        "id": "OhgcX8G1DnJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.autocast(\"cuda\"):\n",
        "    image = pipe(\n",
        "        [prompt] * 1,\n",
        "        guidance_scale=7.5,\n",
        "        latents = latents,\n",
        "    )[0]\n",
        "\n",
        "image[0]"
      ],
      "metadata": {
        "id": "fYA9wgpMBLm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Terrier in the style of Vermeer\"\n",
        "\n",
        "with torch.autocast(\"cuda\"):\n",
        "    image = pipe(\n",
        "        [prompt] * 1,\n",
        "        guidance_scale=7.5,\n",
        "        latents = latents,\n",
        "    )[0]\n",
        "\n",
        "image[0]"
      ],
      "metadata": {
        "id": "vIa-VqGqBWyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Labrador in the style of Van Gogh\"\n",
        "\n",
        "with torch.autocast(\"cuda\"):\n",
        "    image = pipe(\n",
        "        [prompt] * 1,\n",
        "        guidance_scale=7.5,\n",
        "        latents = latents,\n",
        "    )[0]\n",
        "\n",
        "image[0]"
      ],
      "metadata": {
        "id": "bEx7Mf8aBeUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Clown in the style of Vermeer\"\n",
        "\n",
        "with torch.autocast(\"cuda\"):\n",
        "    image = pipe(\n",
        "        [prompt] * 1,\n",
        "        guidance_scale=7.5,\n",
        "        latents = latents,\n",
        "    )[0]\n",
        "\n",
        "image[0]"
      ],
      "metadata": {
        "id": "Th0zprnwBj9x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}