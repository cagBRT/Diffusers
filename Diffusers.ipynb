{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMxxvwJwfJEgAryxj5ZepEv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Diffusers/blob/main/Diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diffusers <br>\n",
        "This notebook demostrates usage of:<br>\n",
        ">## Latent Diffusion Model <br>\n",
        ">## Stable Diffusion Model"
      ],
      "metadata": {
        "id": "5K46QeSVpcvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "App doesn't work\n",
        "https://huggingface.co/spaces/CompVis/text2img-latent-diffusion\n"
      ],
      "metadata": {
        "id": "8YpbfNM1XWll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -s https://github.com/cagBRT/Diffusers.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "metadata": {
        "id": "jnxqla8_yUTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da62aa7f-3057-4e29-90c4-3f200084fee1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "remote: Enumerating objects: 639, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 639 (delta 80), reused 9 (delta 9), pack-reused 494\u001b[K\n",
            "Receiving objects: 100% (639/639), 247.67 MiB | 20.07 MiB/s, done.\n",
            "Resolving deltas: 100% (248/248), done.\n",
            "/content/cloned-repo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "6puqIFUEybrT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers"
      ],
      "metadata": {
        "id": "vBQpjpSdTzAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d92f727-116d-4a83-ab14-9141bb64c372"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "LuRLA9WRGSpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645a04a3-095a-4249-aea0-fea1e3bd035f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall diffusers\n",
        "!pip install diffusers"
      ],
      "metadata": {
        "id": "4eBbF03aTX1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e37e026-2b0c-4f7a-946d-7f80531d9856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers\n",
            "  Downloading diffusers-0.20.2.tar.gz (989 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.1/989.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (6.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.16.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.3.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers) (23.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2023.7.22)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.20.2-py3-none-any.whl size=1342633 sha256=b9702cf75b46436fcccfbf99750f6f3419748002d25b45f580a14f27876f8845\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/8b/d9/34f7a1936109e05e9bba0cc2241a6f8cd89e25959dc7aae942\n",
            "Successfully built diffusers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries"
      ],
      "metadata": {
        "id": "8hmRwTsPCRC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "VQbwcx6lUGPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "YiZq5ZsYY1XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the diffusers library"
      ],
      "metadata": {
        "id": "3DqpDvaZCYjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
        "from pprint import pprint\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "import torch\n",
        "from transformers import TFAutoModelForMaskedLM, AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, top_k_top_p_filtering\n",
        "from torch import nn\n",
        "from accelerate import Accelerator\n",
        "from diffusers import DiffusionPipeline"
      ],
      "metadata": {
        "id": "OBIdMj7HalFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler\n",
        "from diffusers import StableDiffusionPipeline"
      ],
      "metadata": {
        "id": "d6ZOl7VqV2iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High-Resolution Image Synthesis with Latent Diffusion Models (LDM)<br>\n"
      ],
      "metadata": {
        "id": "u_ndBybvDHy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CompVis/ldm-text2im-large-256 is a High-Resolution Image Synthesis with Latent Diffusion Models (LDM)\n",
        "\n",
        "It is atext-to-image model"
      ],
      "metadata": {
        "id": "0WooGYrmfDM3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJSp5vXeTUfG"
      },
      "outputs": [],
      "source": [
        "model_id = \"CompVis/ldm-text2im-large-256\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DiffusionPipeline class is the simplest and most generic way to load any diffusion model from the Hub. <br>\n",
        "\n",
        "The DiffusionPipeline.from_pretrained() method detects the correct pipeline class from the checkpoint, downloads and caches all the required configuration and weight files, and returns a pipeline instance ready for inference."
      ],
      "metadata": {
        "id": "VKbkiCk3sYYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load text input to diffusion pipeline\n",
        "ldm = DiffusionPipeline.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "aPiokKXubxne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note that text-to-image models are known to sometimes produce harmful content.**"
      ],
      "metadata": {
        "id": "Zsz6swzLs8XQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can change the number of inference steps using the num_inference_steps argument.<br><br>\n",
        "\n",
        "**In general, results are better the more steps you use, however the more steps, the longer the generation takes**. <br>\n",
        "Diffusion models work quite well with a relatively small number of steps, the default number of inference steps of 50. <br>\n",
        "If you want faster results you can use a smaller number. <br>\n",
        "If you want potentially higher quality results, you can use larger numbers."
      ],
      "metadata": {
        "id": "z7gOikOrtxBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schedulers**<br>\n",
        "Schedulers in the library take in the output of a trained model, a sample which the diffusion process is iterating on, and a timestep to return a denoised sample.\n",
        "\n"
      ],
      "metadata": {
        "id": "WX-NPvDX0Sti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference (sample random noise and denoise)\n",
        "prompt = \"A painting of a squirrel eating a banana\"\n",
        "images = ldm([prompt], num_inference_steps=50, eta=.3, guidance_scale=6)"
      ],
      "metadata": {
        "id": "dD7CFB9xTgSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If at some point you get a black image, it may be because the content filter built inside the model might have detected an NSFW (not safe for work) result. If you believe this shouldn't be the case, try tweaking your prompt or using a different seed. In fact, the model predictions include information about whether NSFW was detected for a particular result"
      ],
      "metadata": {
        "id": "fSbfQDYFtZ_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generated images of the prompt<br>\n",
        ">\"A painting of a squirrel eating a banana\""
      ],
      "metadata": {
        "id": "fhWUJ-Y25jrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images.images[0]"
      ],
      "metadata": {
        "id": "p4chzf6bTiQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The images below are from previous runs of the model with the same prompt"
      ],
      "metadata": {
        "id": "sKDyqJEOf0SB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"squirrel1.png\" , width=300)"
      ],
      "metadata": {
        "id": "C-pLfcTlyizG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"squirrel2.png\" , width=300)"
      ],
      "metadata": {
        "id": "pqdJD7JUypQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generated images of the prompt<br>\n",
        ">\"A photo of a squirrel eating a banana\""
      ],
      "metadata": {
        "id": "CKZghvjI5rqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"squirrel3.png\" , width=300)"
      ],
      "metadata": {
        "id": "lyuFUc4Myqky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"squirrel4.png\" , width=300)"
      ],
      "metadata": {
        "id": "EwrRBUkwysZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"squirrel5.png\" , width=300)"
      ],
      "metadata": {
        "id": "1qMEWQ-2yuI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "p5rmTFFKrvQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stable Diffusion<br>\n",
        "Stable Diffusion is a text-to-image latent diffusion model created by the researchers and engineers from CompVis, Stability AI and LAION. <br>\n",
        "It is trained on 512x512 images from a subset of the LAION-5B database. <br>\n",
        "\n",
        "LAION-5B is the largest, freely accessible multi-modal dataset that currently exists."
      ],
      "metadata": {
        "id": "fFPPG_hlq9ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install diffusers==0.10.2 transformers scipy ftfy accelerate\n",
        "from diffusers import LMSDiscreteScheduler\n",
        "from diffusers import StableDiffusionPipeline"
      ],
      "metadata": {
        "id": "7eOLM8mHrsDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Stable Diffusion model can be run in inference with just a couple of lines using the StableDiffusionPipeline pipeline. The pipeline sets up everything you need to generate images from text with a simple from_pretrained function call."
      ],
      "metadata": {
        "id": "53DS68OkrdWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next example will take a while to run because it has 1000 timesteps. <br>\n",
        "This gives a photorealistic image, but is time consuming."
      ],
      "metadata": {
        "id": "2MfBgtEj2VyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"CompVis/stable-diffusion-v1-3\"\n",
        "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012,\n",
        "                                 beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler)\n",
        "#pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "rpfdaZoeV7bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code will run much faster with a GPU, but as this is the free version of CoLab, so the GPU may not be available."
      ],
      "metadata": {
        "id": "-b4WZ4c9rzwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_images=3\n",
        "prompt = [\"a photo of an astronaut riding a horse on mars\"]#*num_images\n",
        "#with autocast(\"cuda\"):"
      ],
      "metadata": {
        "id": "M1U2E0NAcUaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = pipe(prompt, guidance_scale=7.5)[0]"
      ],
      "metadata": {
        "id": "lgAZhfHEfV9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images[0]"
      ],
      "metadata": {
        "id": "WTIOFQJmiPzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Geenrated images of the prompt:<br>\n",
        ">\"a photo of an astronaut riding a horse on mars\""
      ],
      "metadata": {
        "id": "ZLK5qL2K6LnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"/content/cloned-repo/astro1.png\" , width=300)"
      ],
      "metadata": {
        "id": "vV9p68sC5Eb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the horses legs in this image. <br>\n"
      ],
      "metadata": {
        "id": "2JDsKmOz7I1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"/content/cloned-repo/astro7.png\" , width=300)"
      ],
      "metadata": {
        "id": "VF-zgWNg7CqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"/content/cloned-repo/astro2.png\" , width=300)"
      ],
      "metadata": {
        "id": "A2fUEucg58Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"/content/cloned-repo/astro3.png\" , width=300)"
      ],
      "metadata": {
        "id": "jy6_hTG-58eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Images generated with fewer timesteps"
      ],
      "metadata": {
        "id": "1uObAG8W6cvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"/content/cloned-repo/astro4.png\" , width=300)"
      ],
      "metadata": {
        "id": "EvMpwzWg58lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"/content/cloned-repo/astro5.png\" , width=600)"
      ],
      "metadata": {
        "id": "58aiKhFO58pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"/content/cloned-repo/astro6.png\" , width=300)"
      ],
      "metadata": {
        "id": "C5JZFfYk58tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "63DLGvtQy6Z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering<br>\n",
        "An interesting trend to have appeared since the release of the big three diffusion models (DALL-E 2, Imagen, and Midjourney) is the increased focus on something called “prompt engineering”.<br>\n",
        "\n",
        "Prompt engineering is literally the “engineering” of prompts to achieve the desired result. <br><br>\n",
        "**For example:** <br>\n",
        ">many people have found that adding “in 4K” or “rendered in Unity” can enhance the realism of images generated by the big three (despite none of them generating in 4K resolution)."
      ],
      "metadata": {
        "id": "GJ8NcnkAxFJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment**<br>\n",
        "1. Change the number of inference steps\n",
        "Run the code to generate a new image\n",
        "\n",
        "2. Change the prompt. Try different wording with the prompt and observe the differences"
      ],
      "metadata": {
        "id": "-mzKXH6Hodx5"
      }
    }
  ]
}