{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPK79g7AejID3sqwkurI8xH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Diffusers/blob/main/diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/spaces/CompVis/text2img-latent-diffusion\n",
        "\n",
        "app to try"
      ],
      "metadata": {
        "id": "8YpbfNM1XWll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers"
      ],
      "metadata": {
        "id": "vBQpjpSdTzAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "LuRLA9WRGSpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
        "from pprint import pprint\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "import torch\n",
        "from transformers import TFAutoModelForMaskedLM, AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, top_k_top_p_filtering\n",
        "from torch import nn\n",
        "from accelerate import Accelerator"
      ],
      "metadata": {
        "id": "OBIdMj7HalFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall diffusers\n",
        "!pip install diffusers\n"
      ],
      "metadata": {
        "id": "4eBbF03aTX1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "YiZq5ZsYY1XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "VQbwcx6lUGPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
        "from pprint import pprint\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "import torch\n",
        "from transformers import TFAutoModelForMaskedLM, AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, top_k_top_p_filtering\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "7r3IfhO1UbWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from diffusers import DiffusionPipeline\n",
        "from diffusers import StableDiffusionPipeline"
      ],
      "metadata": {
        "id": "3-iogRCIXMsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJSp5vXeTUfG"
      },
      "outputs": [],
      "source": [
        "model_id = \"CompVis/ldm-text2im-large-256\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load text input to diffusion pipeline\n",
        "ldm = DiffusionPipeline.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "aPiokKXubxne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference (sample random noise and denoise)\n",
        "prompt = \"A painting of a squirrel eating a banana\"\n",
        "images = ldm([prompt], num_inference_steps=50, eta=.3, guidance_scale=6)"
      ],
      "metadata": {
        "id": "dD7CFB9xTgSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.images[0]"
      ],
      "metadata": {
        "id": "p4chzf6bTiQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "p5rmTFFKrvQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stable Diffusion**<br>\n",
        "Stable Diffusion is a text-to-image latent diffusion model created by the researchers and engineers from CompVis, Stability AI and LAION. <br>\n",
        "It is trained on 512x512 images from a subset of the LAION-5B database. <br>\n",
        "\n",
        "LAION-5B is the largest, freely accessible multi-modal dataset that currently exists."
      ],
      "metadata": {
        "id": "fFPPG_hlq9ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install diffusers==0.10.2 transformers scipy ftfy accelerate"
      ],
      "metadata": {
        "id": "7eOLM8mHrsDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler\n",
        "from diffusers import StableDiffusionPipeline"
      ],
      "metadata": {
        "id": "d6ZOl7VqV2iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Stable Diffusion model can be run in inference with just a couple of lines using the StableDiffusionPipeline pipeline. The pipeline sets up everything you need to generate images from text with a simple from_pretrained function call."
      ],
      "metadata": {
        "id": "53DS68OkrdWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"CompVis/stable-diffusion-v1-3\"\n",
        "# Use the K-LMS scheduler here instead\n",
        "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler)\n",
        "#pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "rpfdaZoeV7bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code will run much faster with a GPU, but as this is the free version of CoLab, so the GPU may not be available."
      ],
      "metadata": {
        "id": "-b4WZ4c9rzwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
        "#with autocast(\"cuda\"):"
      ],
      "metadata": {
        "id": "M1U2E0NAcUaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = pipe(prompt, guidance_scale=7.5)[0]"
      ],
      "metadata": {
        "id": "lgAZhfHEfV9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image[0]"
      ],
      "metadata": {
        "id": "WTIOFQJmiPzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment**<br>\n",
        "Change the number of inference steps\n",
        "Run the code to generate a new image"
      ],
      "metadata": {
        "id": "-mzKXH6Hodx5"
      }
    }
  ]
}