{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNOcKpI/L9Ny9mxvR8J06Tp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Diffusers/blob/main/diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/spaces/CompVis/text2img-latent-diffusion\n",
        "\n",
        "app to try"
      ],
      "metadata": {
        "id": "8YpbfNM1XWll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -s https://github.com/cagBRT/Diffusers.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "metadata": {
        "id": "jnxqla8_yUTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "6puqIFUEybrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers"
      ],
      "metadata": {
        "id": "vBQpjpSdTzAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "LuRLA9WRGSpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries"
      ],
      "metadata": {
        "id": "8hmRwTsPCRC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "VQbwcx6lUGPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "YiZq5ZsYY1XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
        "from pprint import pprint\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "import torch\n",
        "from transformers import TFAutoModelForMaskedLM, AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, top_k_top_p_filtering\n",
        "from torch import nn\n",
        "from accelerate import Accelerator\n",
        "from diffusers import DiffusionPipeline"
      ],
      "metadata": {
        "id": "OBIdMj7HalFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the diffusers library"
      ],
      "metadata": {
        "id": "3DqpDvaZCYjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall diffusers\n",
        "!pip install diffusers"
      ],
      "metadata": {
        "id": "4eBbF03aTX1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler\n",
        "from diffusers import StableDiffusionPipeline"
      ],
      "metadata": {
        "id": "d6ZOl7VqV2iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High-Resolution Image Synthesis with Latent Diffusion Models (LDM)<br>\n"
      ],
      "metadata": {
        "id": "u_ndBybvDHy-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJSp5vXeTUfG"
      },
      "outputs": [],
      "source": [
        "model_id = \"CompVis/ldm-text2im-large-256\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DiffusionPipeline class is the simplest and most generic way to load any diffusion model from the Hub. <br>\n",
        "\n",
        "The DiffusionPipeline.from_pretrained() method detects the correct pipeline class from the checkpoint, downloads and caches all the required configuration and weight files, and returns a pipeline instance ready for inference."
      ],
      "metadata": {
        "id": "VKbkiCk3sYYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load text input to diffusion pipeline\n",
        "ldm = DiffusionPipeline.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "aPiokKXubxne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note that text-to-image models are known tosometimes produce harmful content.**"
      ],
      "metadata": {
        "id": "Zsz6swzLs8XQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can change the number of inference steps using the num_inference_steps argument.<br><br>\n",
        "\n",
        "In general, results are better the more steps you use, however the more steps, the longer the generation takes. <br>\n",
        "Stable Diffusion works quite well with a relatively small number of steps, the default number of inference steps of 50. <br>\n",
        "If you want faster results you can use a smaller number. <br>\n",
        "If you want potentially higher quality results, you can use larger numbers."
      ],
      "metadata": {
        "id": "z7gOikOrtxBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schedulers**<br>\n",
        "Schedulers in the library take in the output of a trained model, a sample which the diffusion process is iterating on, and a timestep to return a denoised sample.\n",
        "\n"
      ],
      "metadata": {
        "id": "WX-NPvDX0Sti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference (sample random noise and denoise)\n",
        "prompt = \"A painting of a squirrel eating a banana\"\n",
        "images = ldm([prompt], num_inference_steps=50, eta=.3, guidance_scale=6)"
      ],
      "metadata": {
        "id": "dD7CFB9xTgSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If at some point you get a black image, it may be because the content filter built inside the model might have detected an NSFW (not safe for work) result. If you believe this shouldn't be the case, try tweaking your prompt or using a different seed. In fact, the model predictions include information about whether NSFW was detected for a particular result"
      ],
      "metadata": {
        "id": "fSbfQDYFtZ_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generated images of the prompt<br>\n",
        ">\"A painting of a squirrel eating a banana\""
      ],
      "metadata": {
        "id": "fhWUJ-Y25jrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images.images[0]"
      ],
      "metadata": {
        "id": "p4chzf6bTiQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"squirrel1.png\" , width=300)"
      ],
      "metadata": {
        "id": "C-pLfcTlyizG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"squirrel2.png\" , width=300)"
      ],
      "metadata": {
        "id": "pqdJD7JUypQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generated images of the prompt<br>\n",
        ">\"A photo of a squirrel eating a banana\""
      ],
      "metadata": {
        "id": "CKZghvjI5rqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"squirrel3.png\" , width=300)"
      ],
      "metadata": {
        "id": "lyuFUc4Myqky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"squirrel4.png\" , width=300)"
      ],
      "metadata": {
        "id": "EwrRBUkwysZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"squirrel5.png\" , width=300)"
      ],
      "metadata": {
        "id": "1qMEWQ-2yuI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "p5rmTFFKrvQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stable Diffusion**<br>\n",
        "Stable Diffusion is a text-to-image latent diffusion model created by the researchers and engineers from CompVis, Stability AI and LAION. <br>\n",
        "It is trained on 512x512 images from a subset of the LAION-5B database. <br>\n",
        "\n",
        "LAION-5B is the largest, freely accessible multi-modal dataset that currently exists."
      ],
      "metadata": {
        "id": "fFPPG_hlq9ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install diffusers==0.10.2 transformers scipy ftfy accelerate\n",
        "from diffusers import LMSDiscreteScheduler\n",
        "from diffusers import StableDiffusionPipeline"
      ],
      "metadata": {
        "id": "7eOLM8mHrsDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Stable Diffusion model can be run in inference with just a couple of lines using the StableDiffusionPipeline pipeline. The pipeline sets up everything you need to generate images from text with a simple from_pretrained function call."
      ],
      "metadata": {
        "id": "53DS68OkrdWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next example will take a while to run because it has 1000 timesteps. <br>\n",
        "This gives a photorealistic image, but is time consuming."
      ],
      "metadata": {
        "id": "2MfBgtEj2VyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"CompVis/stable-diffusion-v1-3\"\n",
        "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012,\n",
        "                                 beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler)\n",
        "#pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "rpfdaZoeV7bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code will run much faster with a GPU, but as this is the free version of CoLab, so the GPU may not be available."
      ],
      "metadata": {
        "id": "-b4WZ4c9rzwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_images=3\n",
        "prompt = [\"a photo of an astronaut riding a horse on mars\"]#*num_images\n",
        "#with autocast(\"cuda\"):"
      ],
      "metadata": {
        "id": "M1U2E0NAcUaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = pipe(prompt, guidance_scale=7.5)[0]"
      ],
      "metadata": {
        "id": "lgAZhfHEfV9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images[0]"
      ],
      "metadata": {
        "id": "WTIOFQJmiPzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Geenrated images of the prompt:<br>\n",
        ">\"a photo of an astronaut riding a horse on mars\""
      ],
      "metadata": {
        "id": "ZLK5qL2K6LnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"astro1.png\" , width=300)"
      ],
      "metadata": {
        "id": "vV9p68sC5Eb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"astro2.png\" , width=300)"
      ],
      "metadata": {
        "id": "A2fUEucg58Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"astro3.png\" , width=300)"
      ],
      "metadata": {
        "id": "jy6_hTG-58eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image generated with fewer timesteps"
      ],
      "metadata": {
        "id": "1uObAG8W6cvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"astro4.png\" , width=300)"
      ],
      "metadata": {
        "id": "EvMpwzWg58lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"astro5.png\" , width=600)"
      ],
      "metadata": {
        "id": "58aiKhFO58pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"astro6.png\" , width=300)"
      ],
      "metadata": {
        "id": "C5JZFfYk58tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "63DLGvtQy6Z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering<br>\n",
        "An interesting trend to have appeared since the release of the big three diffusion models (DALL-E 2, Imagen, and Midjourney) is the increased focus on something called “prompt engineering”.<br>\n",
        "\n",
        "Prompt engineer is literally the “engineering” of prompts to achieve the desired result. <br><br>\n",
        "**For example:** <br>\n",
        ">many people have found that adding “in 4K” or “rendered in Unity” can enhance the realism of images generated by the big three (despite none of them generating in 4K resolution)."
      ],
      "metadata": {
        "id": "GJ8NcnkAxFJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment**<br>\n",
        "1. Change the number of inference steps\n",
        "Run the code to generate a new image\n",
        "\n",
        "2. Change the prompt. Try different wording with the prompt and observe the differences"
      ],
      "metadata": {
        "id": "-mzKXH6Hodx5"
      }
    }
  ]
}