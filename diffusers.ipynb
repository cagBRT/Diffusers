{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOxCZwj/oyTAh66ZVltgqkR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Diffusers/blob/main/diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/spaces/CompVis/text2img-latent-diffusion\n",
        "\n",
        "app to try"
      ],
      "metadata": {
        "id": "8YpbfNM1XWll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers"
      ],
      "metadata": {
        "id": "vBQpjpSdTzAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "LuRLA9WRGSpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
        "from pprint import pprint\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "import torch\n",
        "from transformers import TFAutoModelForMaskedLM, AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, top_k_top_p_filtering\n",
        "from torch import nn\n",
        "from accelerate import Accelerator"
      ],
      "metadata": {
        "id": "OBIdMj7HalFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall diffusers\n",
        "!pip install diffusers\n"
      ],
      "metadata": {
        "id": "4eBbF03aTX1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "YiZq5ZsYY1XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "VQbwcx6lUGPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
        "from pprint import pprint\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "import torch\n",
        "from transformers import TFAutoModelForMaskedLM, AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, top_k_top_p_filtering\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "7r3IfhO1UbWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from diffusers import DiffusionPipeline\n",
        "from diffusers import StableDiffusionPipeline"
      ],
      "metadata": {
        "id": "3-iogRCIXMsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJSp5vXeTUfG"
      },
      "outputs": [],
      "source": [
        "model_id = \"CompVis/ldm-text2im-large-256\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load text input to diffusion pipeline\n",
        "ldm = DiffusionPipeline.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "aPiokKXubxne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference (sample random noise and denoise)\n",
        "prompt = \"A painting of a squirrel eating a banana\"\n",
        "images = ldm([prompt], num_inference_steps=50, eta=.3, guidance_scale=6)"
      ],
      "metadata": {
        "id": "dD7CFB9xTgSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.images[0]"
      ],
      "metadata": {
        "id": "p4chzf6bTiQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "model_id = \"CompVis/stable-diffusion-v1-3\"\n",
        "# Use the K-LMS scheduler here instead\n",
        "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
        "with autocast(\"cuda\"):\n",
        "    image = pipe(prompt, guidance_scale=7.5)[\"sample\"][0]\n",
        "\n",
        "image.save(\"astronaut_rides_horse.png\")"
      ],
      "metadata": {
        "id": "lgAZhfHEfV9d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}